{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree \n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1,3,4,5,6,7,5])\n",
    "y = np.array([0,0,0,0,0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.387755102040817"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean((x-np.mean(x))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.14285714,  0.        ,  0.14285714,  0.14285714,\n",
       "        0.28571429,  0.14285714,  0.14285714])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(x)/sum(np.bincount(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5216406363433181"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-sum([p* np.log2(p) for p in np.bincount(x)/np.sum(np.bincount(x)) if p > 0 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81632653061224492"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-sum([(i/np.sum(np.bincount(x)))**2 for i in np.bincount(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.zeros(3)[y[0]]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob=np.zeros(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob[y[0]]=1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  0.])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.array([1,1,1,1,1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.,  3.])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array([[1,2,3],[2,3,4]])\n",
    "np.mean(y,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.42857143,  0.57142857])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(y,minlength=2)/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1,2,3,4],[2,3,4,5],[4,5,6,3],[3,2,5,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False,  True, False], dtype=bool)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:,1]>3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "N,M = X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(M,2,replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.array([1,0,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for i in np.random.choice(M,2,replace=False):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "levels=np.unique(X[:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 5, 3, 6])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 4, 5, 6])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-bab1a43671ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "vals=X[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 4, 5, 6])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 5, 3, 6])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.5,  4.5,  5.5])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(levels[:-1]+levels[1:])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 5, 6])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "levels[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81127812445913283"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-sum([p*np.log2(p) for p in np.bincount(Y)/len(Y) if p>0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "left=np.argwhere(vals<=3.5).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "right=np.argwhere(vals>3.5).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals=np.array([4, 5, 3, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91829583405448956"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-sum([p*np.log2(p) for p in np.bincount(Y[right])/len(right) if p>0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[left]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_l,n_r = 1,3\n",
    "e_l,e_r = -0.0,0.91829"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_l/n *e_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `ininstance` not found.\n"
     ]
    }
   ],
   "source": [
    "?ininstance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "seed = 3\n",
    "\n",
    "if seed:\n",
    "    n=np.random.seed(seed)\n",
    "    print(n)\n",
    "    print(np.random.seed(seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'v_seed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-611451f5b7b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mv_seed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'v_seed' is not defined"
     ]
    }
   ],
   "source": [
    "v_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用Numpy重写 Decision Tree\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([1,2,3,4,5,6])\n",
    "Y = np.array([0,1,0,0,1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#先从简单的代码进行处理，例如定义函数的评估函数\n",
    "def mse(y):\n",
    "    return np.mean((y - np.mean(y))**2)\n",
    "\n",
    "def entropy(y):\n",
    "    hist = np.bincount(y)\n",
    "    ps = hist /np.sum(hist)\n",
    "    return  -np.sum([p*np.log2(p) for p in ps if p > 0])\n",
    "def gini(y):\n",
    "    hist = np.bincount(y)\n",
    "    ps = hist/np.sum(hist)\n",
    "    return 1- np.sum([i**2 for i in ps])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.222222222222\n",
      "0.918295834054\n",
      "0.444444444444\n"
     ]
    }
   ],
   "source": [
    "print(mse(Y))\n",
    "print(entropy(Y))\n",
    "print(gini(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.222222222222\n",
      "0.918295834054\n",
      "0.444444444444\n"
     ]
    }
   ],
   "source": [
    "print(mse(Y))\n",
    "print(entropy(Y))\n",
    "print(gini(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y):\n",
    "    \"\"\"\n",
    "    Mean squared error for decision tree (ie., mean) predictions\n",
    "    \"\"\"\n",
    "    return np.mean((y - np.mean(y)) ** 2)\n",
    "\n",
    "\n",
    "def entropy(y):\n",
    "    \"\"\"\n",
    "    Entropy of a label sequence\n",
    "    \"\"\"\n",
    "    hist = np.bincount(y)\n",
    "    ps = hist / np.sum(hist)\n",
    "    return -np.sum([p * np.log2(p) for p in ps if p > 0])\n",
    "\n",
    "\n",
    "def gini(y):\n",
    "    \"\"\"\n",
    "    Gini impurity (local entropy) of a label sequence\n",
    "    \"\"\"\n",
    "    hist = np.bincount(y)\n",
    "    N = np.sum(hist)\n",
    "    return 1 - sum([(i / N) ** 2 for i in hist])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 和学习看的模仿资料一样，主要难点是在于分裂上，这点对于没有怎么写类的我来说还是比较困难\n",
    "# 目前的策略就是先模仿写这再去改进\n",
    "# 需要克服的难点是转变思维 不再是过程上的变成而是面向对象的变编程，不过就理解为模版 属性方法之类的东西吧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "choice(a, size=None, replace=True, p=None)\n",
       "\n",
       "Generates a random sample from a given 1-D array\n",
       "\n",
       "        .. versionadded:: 1.7.0\n",
       "\n",
       "Parameters\n",
       "-----------\n",
       "a : 1-D array-like or int\n",
       "    If an ndarray, a random sample is generated from its elements.\n",
       "    If an int, the random sample is generated as if a was np.arange(n)\n",
       "size : int or tuple of ints, optional\n",
       "    Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
       "    ``m * n * k`` samples are drawn.  Default is None, in which case a\n",
       "    single value is returned.\n",
       "replace : boolean, optional\n",
       "    Whether the sample is with or without replacement\n",
       "p : 1-D array-like, optional\n",
       "    The probabilities associated with each entry in a.\n",
       "    If not given the sample assumes a uniform distribution over all\n",
       "    entries in a.\n",
       "\n",
       "Returns\n",
       "--------\n",
       "samples : 1-D ndarray, shape (size,)\n",
       "    The generated random samples\n",
       "\n",
       "Raises\n",
       "-------\n",
       "ValueError\n",
       "    If a is an int and less than zero, if a or p are not 1-dimensional,\n",
       "    if a is an array-like of size 0, if p is not a vector of\n",
       "    probabilities, if a and p have different lengths, or if\n",
       "    replace=False and the sample size is greater than the population\n",
       "    size\n",
       "\n",
       "See Also\n",
       "---------\n",
       "randint, shuffle, permutation\n",
       "\n",
       "Examples\n",
       "---------\n",
       "Generate a uniform random sample from np.arange(5) of size 3:\n",
       "\n",
       ">>> np.random.choice(5, 3)\n",
       "array([0, 3, 4])\n",
       ">>> #This is equivalent to np.random.randint(0,5,3)\n",
       "\n",
       "Generate a non-uniform random sample from np.arange(5) of size 3:\n",
       "\n",
       ">>> np.random.choice(5, 3, p=[0.1, 0, 0.3, 0.6, 0])\n",
       "array([3, 3, 0])\n",
       "\n",
       "Generate a uniform random sample from np.arange(5) of size 3 without\n",
       "replacement:\n",
       "\n",
       ">>> np.random.choice(5, 3, replace=False)\n",
       "array([3,1,0])\n",
       ">>> #This is equivalent to np.random.permutation(np.arange(5))[:3]\n",
       "\n",
       "Generate a non-uniform random sample from np.arange(5) of size\n",
       "3 without replacement:\n",
       "\n",
       ">>> np.random.choice(5, 3, replace=False, p=[0.1, 0, 0.3, 0.6, 0])\n",
       "array([2, 3, 0])\n",
       "\n",
       "Any of the above can be repeated with an arbitrary array-like\n",
       "instead of just integers. For instance:\n",
       "\n",
       ">>> aa_milne_arr = ['pooh', 'rabbit', 'piglet', 'Christopher']\n",
       ">>> np.random.choice(aa_milne_arr, 5, p=[0.5, 0.1, 0.1, 0.3])\n",
       "array(['pooh', 'pooh', 'pooh', 'Christopher', 'piglet'],\n",
       "      dtype='|S11')\n",
       "\u001b[0;31mType:\u001b[0m      builtin_function_or_method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?np.random.choice()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self,left,right,rule):\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.feature = rule[0]\n",
    "        self.threshold = rule[1]\n",
    "\n",
    "class Leaf:\n",
    "    def __init__(self,value):\n",
    "        self.value = value\n",
    "        \n",
    "#定义好了节点和叶子之后开始进行决策树类的编写，涉及到许多方法，这段对于我而言其实有点搞\n",
    "#对于决策数类的定义这块，可以考虑流程化的角度去看，刚才定义的节点和叶子的时候，其实有点像那种最小化知识的思考\n",
    "#对于刚开始的决策树设计流程而言的话，就假设我是开始弄决策树了，我刚开始的深度肯定为0，根节点还没有。为了开始进行树的生长，我需要选择选择选择的变量，\n",
    "#按照什么标准进行分裂，最大深度是多少，计算叶子的时候，是按照目标是分类变量还是连续值，连续值的话可输出值，离散值的话输出概率，基本就是这思路，如果这样\n",
    "#想的话其实整个程序的思路还是比较清楚的，说白了这个的初始化就是说\n",
    "class DecisionTree:\n",
    "    def __init__(self,classifier =True,max_depth=None,n_feats=None,criterion='entropy',seed=None,):\n",
    "        if seed:\n",
    "            np.random.seed(seed)\n",
    "        \n",
    "        self.depth = 0\n",
    "        self.root = None\n",
    "        \n",
    "        self.n_feats = n_feats\n",
    "        self.criterion = criterion\n",
    "        self.classifier = classifier\n",
    "        self.max_depth = max_depth if max_depth else np.inf\n",
    "        \n",
    "        if not classifier and criterion in ['gini','entropy']:\n",
    "            raise ValueError(\n",
    "                \"{} is a valid criterion only when classifier = True.\".format(criterion)\n",
    "            )\n",
    "        if classifier and criterion == 'mse':\n",
    "            raise ValueError(\"'mse' is a valid criterion only when classifier = Flase.\")\n",
    "            \n",
    "    def fit(self,X,Y):\n",
    "        self.n_classes = max(Y) + 1 if self.classifier else None\n",
    "        self.n_feats = X.shape[1] if not self.n_feats else min(self.n_feats,X.shape[1])\n",
    "        self.root=self._grow(X,Y)\n",
    "        \n",
    "    def predict(self,X):\n",
    "        return np.array([self._traverse(x,self.root) for x in X])\n",
    "    \n",
    "    def predict_class_probs(self,X):\n",
    "        assert self.classifier,\"'predict_calss_probs' undefined for classifier = False\"\n",
    "        return np.array([self._traverse(x,self.root,prob=True) for x in X])\n",
    "#下面的函数才基本上是整个决策树的关键，涉及到了树的生长分割，计算信息增益等基本的计算，不过由于类的饮用稍微还是有点绕\n",
    "#在写这个程序的时候发现作者有个习惯，就是喜欢将那些异常的特殊的情况进行讨论，然后再看正常的情况\n",
    "#要看数据的生长那先看那些情况下我们不进行分割，一个是我分组比较完美，可以分的干净，另一个是达到我最大的学习深度了\n",
    "    def _grow(self,X,Y):\n",
    "        if len(set(Y))==1:\n",
    "            if self.classifer:\n",
    "                prob = np.zeros(self.n_classes)\n",
    "                prob[Y[0]] = 1.0\n",
    "            return Leaf(prob) if self.classifer else Leaf(Y[0])\n",
    "        \n",
    "        if self.depth >= self.max_depth:\n",
    "            v = np.mean(Y,axis=0)\n",
    "            if self.classifier:\n",
    "                v = np.bincount(Y,minlength=self.n_classes) / len(Y)\n",
    "            return Leaf(v)\n",
    "#特殊的情况处理好了之后便开始进行树的生长        \n",
    "        N,M = X.shape\n",
    "        self.depth += 1\n",
    "        feat_idxs = np.random.choice(M,self.n_feats,replace=True)\n",
    "        \n",
    "        feat,thresh = self._segment(X,Y,feat_idxs)\n",
    "        l = np.argwhere(X[:,feat] <= thresh).flatten()\n",
    "        r = np.argwhere(X[:,feat] > thresh).flatten()\n",
    "        \n",
    "#这个转换好不错，我还反应了下，个人觉得好不错,而且还是类的递归\n",
    "        left = self._grow(X[l,:],Y[l])\n",
    "        right = self._grow(X[r,:],Y[r])\n",
    "        return Node(left,right,(feat,thresh))\n",
    "\n",
    "    def _segment(self,X,Y,feat_idxs):\n",
    "        best_gain = -np.inf\n",
    "        split_idx,split_thresh = None,None\n",
    "        for i in feat_idxs:\n",
    "            vals = X[:,i]\n",
    "            levels = np.unique(vals)\n",
    "            thresholds = (levels[:-1]+levels[1:])/2 \n",
    "            gains = np.array([self._impurity_gain(Y,t,vals) for t in thresholds])\n",
    "#关于为什么要这样设置阈值，我都不知道为什么，不过也可以说出个大概来，就是对特征变量的值进行去重排序，取中间值进行阈值的筛选\n",
    "            if gains.max() > best_gain:\n",
    "                split_idx = i\n",
    "                best_gain = gains.max()\n",
    "                split_thresh = thresholds[gains.argmax()]\n",
    "        return split_idx,split_thresh\n",
    "#计算信息增益，分解下来就是简单的母节点的信息熵 - 叶节点的信息熵    \n",
    "    def _impurity_gain(self,Y,split_thresh,feat_values):\n",
    "        if self.criterion == \"entropy\":\n",
    "            loss = entropy\n",
    "        elif self.criterion == \"gini\":\n",
    "            loss = gini\n",
    "        elif self.criterion == \"mse\":\n",
    "            loss = mse\n",
    "        \n",
    "        parent_loss = loss(Y)\n",
    "        \n",
    "        left = np.argwhere(feat_values <= split_thresh).flatten()\n",
    "        right = np.argwhere(feat_values > split_thresh).flatten()\n",
    "        \n",
    "        if len(left) == 0 or len(right) == 0:\n",
    "            return 0\n",
    "#为啥返回0 呢？我也有点纳闷，增益为0？\n",
    "        \n",
    "        n = len(Y)\n",
    "        n_l,n_r = len(left),len(right)\n",
    "        e_l,e_r = loss(Y[left]),loss(Y[right])\n",
    "        child_loss = (n_l/n) * e_l + (n_r/n)*e_r\n",
    "        \n",
    "        ig = parent_loss -child_loss\n",
    "        \n",
    "        return ig\n",
    "# 这里的value是指的叶子节点？这个递归也也太多了吧\n",
    "    def _traverse(self,X,node,prob = False):\n",
    "        if isinstance(node,Leaf):\n",
    "            if self.classifier:\n",
    "                return node.value if prob else node.value.argmax()\n",
    "            return node.value\n",
    "        if X[node.feature] <= node.threshold:\n",
    "            return self._traverse(X,node.left,prob)\n",
    "        return self._traverse(X,node.right,prob)\n",
    "# 这个traversek看的我比较迷，表示需要这个吗\n",
    "    \n",
    "\n",
    "    \n",
    "        #先从简单的代码进行处理，例如定义函数的评估函数\n",
    "    def mse(y):\n",
    "        return np.mean((y - np.mean(y))**2)\n",
    "\n",
    "    def entropy(y):\n",
    "        hist = np.bincount(y)\n",
    "        ps = hist /np.sum(hist)\n",
    "        return  -np.sum([p*np.log2(p) for p in ps if p > 0])\n",
    "    def gini(y):\n",
    "        hist = np.bincount(y)\n",
    "        ps = hist/np.sum(hist)\n",
    "        return 1- np.sum([i**2 for i in ps])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 至此就把简单的决策树给看完了，其实说实在知道理论和实际操作完全是两件事情，有些时候对于数据的处理都没有想好该怎么做，还有递归思想，解决了关于不断分裂的\n",
    "# 问题，这点对于我而言其实还是有借鉴意义，之前高清圆还跟我讨论过这个问题，今天收获了之后还是很用的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这个基本上就是整个决策树的最根基的东西，所以这个代码最好自己要好好看，其实对于生活中的决策这个也是极其有实验意义的 因为这个算法足够的简单\n",
    "# 20191121号去听那个孤独大脑 老喻的讲座无不体现着这个决策树 坦白而言 我并没有觉得老喻将的有多好 他说的那些我都知道 但是我缺的是将这些内容系统化的整理起来\n",
    "# 这才是我的问题，或者说我应该努力去解决的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named '__main__.dt'; '__main__' is not a package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-4cf0f3a6aa2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDecisionTree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named '__main__.dt'; '__main__' is not a package"
     ]
    }
   ],
   "source": [
    "# 随机森林的编写，用到了决策树\n",
    "\n",
    "import numpy as np\n",
    "from .dt import DecisionTree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 3, 0, 4, 0, 0, 6])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用自主法进行有放回的抽样\n",
    "# 不过我对这个代码中为什么会取全量的抽样比较困惑，虽然那样选择也不是全量因为肯定是有对样本有重复的选择\n",
    "# 在写类的时候最大的感受是没有感受到面对过程时需要return什么，这点我自己不是那么理的清楚，更多的是写了很多方法之类的\n",
    "\n",
    "def bootstrap_sample(X,Y):\n",
    "    N,M = X.shape\n",
    "    idxs = np.random.choice(N,N,replace=True)\n",
    "    return X[idxs],Y[idxs]\n",
    "\n",
    "# 进行随机森林的算法\n",
    "class RandomForest:\n",
    "    def __init__(self,n_trees,max_depth,n_feats,classifier=True,criterion = \"enropy\")\n",
    "        self.trees = []\n",
    "        self.n_trees = n_trees\n",
    "        self.max_depth = max_depth\n",
    "        self.n_feats = n_feats\n",
    "        self.classifier = classifier\n",
    "        self.criterion = criterion\n",
    "        \n",
    "    def fit(self,X,Y):\n",
    "        self.trees = []\n",
    "        for _ in range(self.n_tress):\n",
    "            X_samp, Y_samp = bootstrap_sample(X,Y)\n",
    "            tree = DecisionTree(\n",
    "                n_feats = self.n_feats,\n",
    "                max_depth=self.max_depth,\n",
    "                criterion = self.criterion,\n",
    "                classifier = self.classifier,\n",
    "            )\n",
    "            tree.fit(X_samp,Y_samp)\n",
    "            self.trees.append(tree)\n",
    "# 这个append的tree是append的啥 这点我自己其实有点懵\n",
    "# 下面那个调用我自己也有点弄的半懂半不懂的\n",
    "def predict(self,X):\n",
    "    tree_peds = np.array([[t._traverse(x,t.root) for x in X] for t in self.trees])\n",
    "    return self._vote(tree_preds)\n",
    "# 为什么要转置，表示有点懵\n",
    "def _vote(self,predictions):\n",
    "    if self.classifier:\n",
    "        out = [np.bincount(x).argmax() for x in predictions.T]\n",
    "    else:\n",
    "        out = [np.mean(x) for x in prediction.T]\n",
    "    return np.array(out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 代码总的来说还是比较简单的，不过对于里面的内容还是有点不是很理解透彻，主要原因是我需要再去深入的了解我写决策树的时候做的事情，需要理解类\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 开始对做GBDT的代码，在此之前的话需定义一些损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "class ClassProbEstimator:\n",
    "    def fit(self,X,y):\n",
    "        self.class_prob = y.sum() / len(y)\n",
    "        \n",
    "    def predict(self,X):\n",
    "        pred = np.empty(X.shape[0],dtype=np.float64)\n",
    "        pred.fill(self.class_prob)\n",
    "        return pred\n",
    "    \n",
    "class MeanBaseEstimator:\n",
    "    def fit(self,X,y):\n",
    "        self.avg = np.mean(y)\n",
    "        \n",
    "    def predict(self,X):\n",
    "        pred = np.empty(X.shape[0],dtype=np.float64)\n",
    "        pred.fill(self.avg)\n",
    "        return pred\n",
    "# 加入了调用函数，将定义的类的实例也当成函数来\n",
    "# 但是坦白而言没有看到作者后面利用了这个啊，比较困惑那为啥要定义这个\n",
    "class MSELoss:\n",
    "    def __call__(self,y,y_pred):\n",
    "        return np.mean((y - y_pred)**2)\n",
    "        \n",
    "    def base_estimator(self):\n",
    "        return MeanBaseEstimator()\n",
    "# 这个是弄grad定义成这样主要是为了什么呢？这个我有点不是很理解对于我来说\n",
    "# 只能说稍微有点知道了，这个计算梯度和我们如何定义损失函数关，其实不是很知道为什么会有len(y),看系数有2应该就是平方和的感觉啊\n",
    "# 关于len(y)就是那个N的意思，计算的是一个样本的梯度，所以要弄一下\n",
    "    def grad(self,y,y_pred):\n",
    "        return -2 / len(y) * (y - y_pred)\n",
    "# 线性搜索也不是那么的懂，这个h_pred是什么意思\n",
    "# 这里的一个作用就是在调整步长，和作者所说的是调整weight来的有点出入\n",
    "# 这里的设定更多的是输入的时候对步长进行的调整，默认其实还是按照恒定的步长\n",
    "    def line_search(self,y,y_pred,h_pred):\n",
    "        Lp = np.sum((y - y_pred) * h_pred)\n",
    "        Lpp = np.sum(h_pred * h_pred)\n",
    "        \n",
    "        return 1 if np.sum(Lpp) == 0 else Lp / Lpp\n",
    "# 这个eps也看不懂,是machine epsilon 可以理解为计算机在计算存储浮点数不准确，给了一个上限\n",
    "\n",
    "class CrossEntropyLoss:\n",
    "    def __call__(self,y,y_pred):\n",
    "        eps = np.finfo(float).eps\n",
    "        return -np.sum(y * np.log(y_pred + eps))\n",
    "     \n",
    "    def base_estimator(self):\n",
    "        return ClassProbEstimator()\n",
    "    \n",
    "    def grad(self,y,y_pred):\n",
    "        eps = np.finfo(float).eps\n",
    "        return -y* 1/(y_pred + eps)\n",
    "    \n",
    "    def line_search(self,y,y_pred,h_pred):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "# 整个块为什么要这么定义我自己其实并不是很明白，为什么要这样去弄这样的结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2204460492503131e-16"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.finfo(float).eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named '__main__.dt'; '__main__' is not a package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-204b7604c26e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDecisionTree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMSELoss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named '__main__.dt'; '__main__' is not a package"
     ]
    }
   ],
   "source": [
    "# 定义好损失函数之后开始写GBDT的函数\n",
    "# y变量的one_hot编码\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from .dt import DecisionTree\n",
    "from .losses import MSELoss,CrossEntropyLoss\n",
    "\n",
    "def to_one_hot(labels,n_classes=None):\n",
    "    if labels.ndm > 1:\n",
    "        raise ValueError(\"labels must have dimension 1,but got {}\".format(labels.ndim))\n",
    "        \n",
    "    N = labels.size\n",
    "    n_cols = np.max(labels) + 1 if n_classes is None else n_classes\n",
    "    one_hot = np.zeros((N,n_cols))\n",
    "    one_hot[np.arange(N),labels] = 1.0\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(labels,n_classes=None):\n",
    "    if labels.ndim > 1:\n",
    "        raise ValueError(\"labels must have dimension 1,but got {}\".format(labels.ndim))\n",
    "        \n",
    "    N = labels.size\n",
    "    n_cols = np.max(labels) + 1 if n_classes is None else n_classes\n",
    "    one_hot = np.zeros((N,n_cols))\n",
    "    one_hot[np.arange(N),labels] = 1.0\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array([0,1,2,3,4,3,4,4,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = labels.size\n",
    "np.arange(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((N,n_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=labels.size\n",
    "n_cols=np.max(labels)+1\n",
    "one_hot = np.zeros((N,n_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot[np.arange(N),labels] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot[np.arange(N),labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 先上来就定义了一大段感觉也是醉了，这样看的话确实感觉有点尴尬面向对象的语言\n",
    "class GradientBoostedDecisionTree:\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_iter,\n",
    "        max_depth = None,\n",
    "        classifier = True,\n",
    "        learning_rate = 1,\n",
    "        loss = \"crossentropy\",\n",
    "        step_size = \"constant\"\n",
    "    ):\n",
    "        self.loss = loss\n",
    "        self.weights = None\n",
    "        self.learners = None\n",
    "        self.out_dims = None\n",
    "        self.n_iter = n_iter\n",
    "        self.base_estimator = None\n",
    "        self.max_depth = max_depth\n",
    "        self.step_size = step_size\n",
    "        self.classifier = classifier\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "    def fit(self,X,Y):\n",
    "        if self.loss == \"mse\":\n",
    "            loss = MSELoss()\n",
    "        elif self.loss == \"crossentropy\":\n",
    "            loss = CrossEntropyLoss()\n",
    "# 后面那个为什么要那样的变换，这点我不是很懂为啥\n",
    "# 这里是对Y进行的变换，如果是分类的话进行one——hot编码，如果是连续变量且纬度为1的话就变成列变量\n",
    "        if self.classifier:\n",
    "            Y = to_one_hot(Y.flatten())\n",
    "        else:\n",
    "            Y = Y.reshape(-1,1) if len(Y.shape) == 1 else Y\n",
    "    \n",
    "        N, M = X.shape\n",
    "        self.out_dims = Y.shape[1]\n",
    "        self.learners = np.empty((self.n_iter,self.out_dims),dtype=object)\n",
    "        self.weights = np.ones((self.n_iter,self.out_dims))\n",
    "        self.weights[1:,:] *= self.learning_rate\n",
    "# 下面这些也知道是什么但是还是不懂。。。。。   \n",
    "        Y_pred = np.zeros((N,self.out_dims))\n",
    "        for k in range(self.out_dims):\n",
    "            t = loss.base_estimator()\n",
    "            t.fit(X,Y[:,k])\n",
    "            Y_pred[:,k] += t,predict(X)\n",
    "            self.learners[0,k] = t\n",
    "\n",
    "        for i in range(1,self.n_iter):\n",
    "            for k in range(self.out_dims):\n",
    "                y,y_pred = Y[:,k],Y_pred[:,k]\n",
    "                neg_grad = -1 * loss.grad(y,y_pred)\n",
    "\n",
    "                t = DecisionTree(\n",
    "                   classifier = False,max_depth=self.max_depth,criterion=\"mse\"\n",
    "                )\n",
    "\n",
    "                t.fit(X,neg_grad)\n",
    "                self.learners[i,k] = t\n",
    "# \n",
    "                step = 1.0\n",
    "                h_pred = t.predict(X)\n",
    "                if self.step_size == \"adaptive\":\n",
    "                    step = loss.line_search(y,y_pred,h_pred)\n",
    "\n",
    "                self.weight[i,k] *= step\n",
    "                Y_pred[:,k] += self.weight[i,k]*h_pred\n",
    "\n",
    "        \n",
    "    def predict(self,X):\n",
    "        Y_pred = np.zeros((X.shape[0],self.out_dims))\n",
    "        for i in range(self.n_iter):\n",
    "            for k in range(self.out_dims):\n",
    "                Y_pred[:,k] += self.weights[i,k] * self.learners[i,k].predict(X)\n",
    "                \n",
    "        if self.classifier:\n",
    "            Y_pred = Y_pred.argmax(axis = 1)\n",
    "            \n",
    "        return Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([1,0,1,0,0,1,0,0,1,0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33333333333333331"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.sum()/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1,2,3],[2,3,4],[3,4,4],[1,3,4],[2,3,4],[2,2,3],[2,4,1],[2,3,4],[2,3,4],[3,4,3],[1,2,3],[2,3,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.empty(X.shape[0],dtype = np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.fill(y.sum()/len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33333333333333331"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=np.array([1,1,1,0,0,0,1,1,0,1,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.58333333333333337"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean((y - y_pred)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.        ,  0.16666667, -0.        , -0.        , -0.        ,\n",
       "       -0.16666667,  0.16666667,  0.16666667, -0.16666667,  0.16666667,\n",
       "       -0.        ,  0.16666667])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-2/len(y)*(y - y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "N,M = X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dims = Y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.array([1,0,1,0,0,1,0,0,1,0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = to_one_hot(Y.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.]])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dims = Y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "learners = np.empty((3,2),dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.ones((3,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights[1:,:] *= 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = np.zeros((N,out_dims))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(out_dims):\n",
    "    t = CrossEntropyLoss().base_estimator()\n",
    "    t.fit(X,Y[:,k])\n",
    "    Y_pred[:,k] += t.predict(X)\n",
    "    learners[0,k] = t\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<__main__.ClassProbEstimator object at 0x113869278>,\n",
       "        <__main__.ClassProbEstimator object at 0x113869a58>],\n",
       "       [None, None],\n",
       "       [None, None]], dtype=object)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.66666667,  0.33333333],\n",
       "       [ 0.66666667,  0.33333333],\n",
       "       [ 0.66666667,  0.33333333],\n",
       "       [ 0.66666667,  0.33333333],\n",
       "       [ 0.66666667,  0.33333333],\n",
       "       [ 0.66666667,  0.33333333],\n",
       "       [ 0.66666667,  0.33333333],\n",
       "       [ 0.66666667,  0.33333333],\n",
       "       [ 0.66666667,  0.33333333],\n",
       "       [ 0.66666667,  0.33333333],\n",
       "       [ 0.66666667,  0.33333333],\n",
       "       [ 0.66666667,  0.33333333]])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation maximum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-161-c26833a13057>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"mse\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mneg_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mlearners\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-127-c1d5a4002b92>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_feats\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_feats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-127-c1d5a4002b92>\u001b[0m in \u001b[0;36m_grow\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;31m#这个转换好不错，我还反应了下，个人觉得好不错,而且还是类的递归\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mleft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0mright\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mthresh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-127-c1d5a4002b92>\u001b[0m in \u001b[0;36m_grow\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mfeat_idxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_feats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mfeat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mthresh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_segment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeat_idxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mthresh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mthresh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-127-c1d5a4002b92>\u001b[0m in \u001b[0;36m_segment\u001b[0;34m(self, X, Y, feat_idxs)\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0mgains\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_impurity_gain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvals\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthresholds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;31m#关于为什么要这样设置阈值，我都不知道为什么，不过也可以说出个大概来，就是对特征变量的值进行去重排序，取中间值进行阈值的筛选\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mgains\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_gain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m                 \u001b[0msplit_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0mbest_gain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgains\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_amax\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# small reductions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_amax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_maximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_amin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation maximum which has no identity"
     ]
    }
   ],
   "source": [
    "for i in range(1,3):\n",
    "    for k in range(2):\n",
    "        y,y_pred = Y[:,k],Y_pred[:,k]\n",
    "        neg_grad = -1 * CrossEntropyLoss().grad(y,y_pred)\n",
    "        \n",
    "        t = DecisionTree(classifier=False,max_depth=4,criterion=\"mse\")\n",
    "        t.fit(X,neg_grad)\n",
    "        learners[i,k] = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0. ,  1.5,  0. ,  1.5,  1.5,  0. ,  1.5,  1.5,  0. ,  1.5,  1.5,\n",
       "        1.5])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 看GBDT最大的感受就是作者用了多维数组进行组合，这点我个人觉得还是很不错的，我之前类似的用到过，这样走一遍感觉还是很好的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UP = dog()\n",
    "wanzi = dog(color = 'yellow')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
